package mainimport (	"math/rand"	"sync"	"time")// PeerEntry represents one known peer in the PeerList.type PeerEntry struct {	NodeID             string	Address            string	LastSeenMS         int64	PendingPings       int	LastPingIdentifier string // identifier of the most recently sent unanswered PING}// PeerManager manages the bounded PeerList in a thread-safe manner.type PeerManager struct {	mu     sync.RWMutex	selfID string	limit  int	random *rand.Rand	peers  map[string]*PeerEntry // node ID â†’ entry}func newPeerManager(selfID string, limit int, random *rand.Rand) *PeerManager {	return &PeerManager{		selfID: selfID,		limit:  limit,		random: random,		peers:  make(map[string]*PeerEntry, limit),	}}// add inserts or refreshes a peer. Returns true if a new entry was created.func (manager *PeerManager) add(nodeID, address string) bool {	if nodeID == manager.selfID {		return false	}	manager.mu.Lock()	defer manager.mu.Unlock()	if entry, exists := manager.peers[nodeID]; exists {		entry.LastSeenMS = time.Now().UnixMilli()		entry.Address = address		return false	}	if len(manager.peers) >= manager.limit {		manager.evictOne()	}	manager.peers[nodeID] = &PeerEntry{		NodeID:     nodeID,		Address:    address,		LastSeenMS: time.Now().UnixMilli(),	}	return true}func (manager *PeerManager) remove(nodeID string) {	manager.mu.Lock()	delete(manager.peers, nodeID)	manager.mu.Unlock()}func (manager *PeerManager) has(nodeID string) bool {	manager.mu.RLock()	_, exists := manager.peers[nodeID]	manager.mu.RUnlock()	return exists}func (manager *PeerManager) hasByAddress(address string) bool {	manager.mu.RLock()	defer manager.mu.RUnlock()	for _, entry := range manager.peers {		if entry.Address == address {			return true		}	}	return false}func (manager *PeerManager) count() int {	manager.mu.RLock()	n := len(manager.peers)	manager.mu.RUnlock()	return n}func (manager *PeerManager) isFull() bool { return manager.count() >= manager.limit }func (manager *PeerManager) touch(nodeID string) {	manager.mu.Lock()	if entry, exists := manager.peers[nodeID]; exists {		entry.LastSeenMS = time.Now().UnixMilli()	}	manager.mu.Unlock()}func (manager *PeerManager) recordPingSent(nodeID, pingIdentifier string) {	manager.mu.Lock()	if entry, exists := manager.peers[nodeID]; exists {		entry.PendingPings++		entry.LastPingIdentifier = pingIdentifier	}	manager.mu.Unlock()}// recordPong resets pending pings if the ping identifier matches. Returns true on match.func (manager *PeerManager) recordPong(nodeID, pingIdentifier string) bool {	manager.mu.Lock()	defer manager.mu.Unlock()	entry, exists := manager.peers[nodeID]	if !exists || entry.LastPingIdentifier != pingIdentifier {		return false	}	entry.PendingPings = 0	entry.LastSeenMS = time.Now().UnixMilli()	return true}// stale returns peers that have exceeded timeoutSeconds AND have at least// minimumPendingPings unanswered pings.func (manager *PeerManager) stale(timeoutSeconds float64, minimumPendingPings int) []*PeerEntry {	cutoff := time.Now().UnixMilli() - int64(timeoutSeconds*1000)	manager.mu.RLock()	defer manager.mu.RUnlock()	var result []*PeerEntry	for _, entry := range manager.peers {		if entry.LastSeenMS < cutoff && entry.PendingPings >= minimumPendingPings {			result = append(result, entry)		}	}	return result}// all returns a snapshot of every peer entry.func (manager *PeerManager) all() []*PeerEntry {	manager.mu.RLock()	defer manager.mu.RUnlock()	result := make([]*PeerEntry, 0, len(manager.peers))	for _, entry := range manager.peers {		result = append(result, entry)	}	return result}// randomSample returns up to count random peers, excluding the given node IDs.func (manager *PeerManager) randomSample(count int, excludeIDs ...string) []*PeerEntry {	excluded := make(map[string]bool, len(excludeIDs))	for _, id := range excludeIDs {		excluded[id] = true	}	manager.mu.RLock()	candidates := make([]*PeerEntry, 0, len(manager.peers))	for _, entry := range manager.peers {		if !excluded[entry.NodeID] {			candidates = append(candidates, entry)		}	}	manager.mu.RUnlock()	manager.mu.Lock()	manager.random.Shuffle(len(candidates), func(i, j int) {		candidates[i], candidates[j] = candidates[j], candidates[i]	})	manager.mu.Unlock()	if count > len(candidates) {		count = len(candidates)	}	return candidates[:count]}// peerInfoList returns a shuffled slice of PeerInfo for PEERS_LIST payloads.func (manager *PeerManager) peerInfoList(excludeID string, maxPeers int) []PeerInfo {	manager.mu.RLock()	result := make([]PeerInfo, 0, len(manager.peers))	for _, entry := range manager.peers {		if entry.NodeID != excludeID {			result = append(result, PeerInfo{NodeID: entry.NodeID, Address: entry.Address})		}	}	manager.mu.RUnlock()	manager.mu.Lock()	manager.random.Shuffle(len(result), func(i, j int) { result[i], result[j] = result[j], result[i] })	manager.mu.Unlock()	if maxPeers > len(result) {		maxPeers = len(result)	}	return result[:maxPeers]}// evictOne removes the least-responsive peer (most pending pings; ties broken by oldest last seen).// Caller must hold the write lock.func (manager *PeerManager) evictOne() {	var worst *PeerEntry	for _, entry := range manager.peers {		if worst == nil ||			entry.PendingPings > worst.PendingPings ||			(entry.PendingPings == worst.PendingPings && entry.LastSeenMS < worst.LastSeenMS) {			worst = entry		}	}	if worst != nil {		delete(manager.peers, worst.NodeID)	}}